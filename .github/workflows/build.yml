name: ðŸ” Quality Checks & CI

# WEBS-44, WEBS-45: Comprehensive CI/CD pipeline with strict quality gates
# Note: Deployment happens via github-pages.yml when pushing to main
on:
  push:
    branches: [ dev ]  # Only run on dev - main triggers deployment
    paths:
      - 'aethron.tech/**'
      - '.github/workflows/**'
  pull_request:
    branches: [ dev, main ]
    paths:
      - 'aethron.tech/**'
      - '.github/workflows/**'

# Ensure only one workflow runs at a time per branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  issues: write
  actions: read
  contents: read

jobs:
  # Job 1: Linting and Code Quality (runs first, fastest feedback)
  lint:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    
    defaults:
      run:
        working-directory: ./aethron.tech
        
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
        cache-dependency-path: aethron.tech/package-lock.json
        
    - name: Install dependencies
      run: npm ci
      
    - name: Run JavaScript linting
      run: npm run lint:js:check
      continue-on-error: false
      
    - name: Build site (required for HTML linting)
      run: npm run build
      env:
        NODE_ENV: ci
        
    - name: Run HTML linting
      run: npm run lint:html:check
      continue-on-error: false
      
    - name: Run CSS linting
      run: npm run lint:css:check
      continue-on-error: false
      
    - name: âœ… Linting Summary
      run: |
        echo "ðŸŽ‰ All linting checks passed successfully!"
        echo "âœ… JavaScript (ESLint): PASSED"
        echo "âœ… HTML (HTMLHint): PASSED" 
        echo "âœ… CSS (Stylelint): PASSED"

  # Job 2: Build and Test (runs after linting passes)
  build:
    name: Build & Test
    runs-on: ubuntu-latest
    needs: lint  # Only run after linting passes
    
    defaults:
      run:
        working-directory: ./aethron.tech
    
    # Test on Node.js 20.x (primary) and 18.x (compatibility)
    strategy:
      matrix:
        node-version: [18.x, 20.x]
      fail-fast: false  # Continue testing other versions if one fails
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Setup Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
        cache-dependency-path: aethron.tech/package-lock.json
        
    - name: Install dependencies
      run: npm ci
      
    - name: Check for vulnerabilities (npm audit)
      run: npm audit --audit-level=moderate --production
      continue-on-error: false
      
    - name: Build website
      run: npm run build
      env:
        NODE_ENV: ci
        
    - name: Verify build success
      run: |
        if [ ! -d "_site" ]; then
          echo "âŒ Build failed: _site directory not found"
          exit 1
        fi
        if [ ! -f "_site/index.html" ]; then
          echo "âŒ Build failed: index.html not found in _site"
          exit 1
        fi
        echo "âœ… Build successful: _site directory contains expected files"
        echo "ðŸ“Š Build statistics:"
        echo "   - Total files: $(find _site/ -type f | wc -l)"
        echo "   - HTML files: $(find _site/ -name '*.html' | wc -l)"
        echo "   - Build size: $(du -sh _site/ | cut -f1)"
        
    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: aethron-tech-build-node${{ matrix.node-version }}
        path: aethron.tech/_site/
        retention-days: 7

    - name: List node_modules/.bin before SBOM
      run: ls -l node_modules/.bin
      working-directory: ./aethron.tech

    - name: Generate SBOM (CycloneDX)
      run: npm run sbom:generate
      working-directory: ./aethron.tech
      continue-on-error: false

    - name: Upload SBOM artifact
      uses: actions/upload-artifact@v4
      with:
        name: sbom
        path: aethron.tech/sbom/sbom.json
        retention-days: 30

    - name: Run npm audit (dependency vulnerability scan)
      run: |
        echo "ðŸ” Running npm audit for vulnerabilities..."
        npm audit --audit-level=moderate --json > audit-report.json || true
        cat audit-report.json | jq '.metadata.vulnerabilities' || true
        if grep -q '"critical": 0' audit-report.json && grep -q '"high": 0' audit-report.json; then
          echo "âœ… No critical or high vulnerabilities found."
        else
          echo "âš ï¸ Vulnerabilities found. See audit-report.json for details."
        fi
      continue-on-error: true
      env:
        NODE_ENV: ci

  # Job 3: Quality Checks (Lighthouse, Pa11y, Performance) - runs after build
  quality:
    name: Quality & Performance Audit  
    runs-on: ubuntu-latest
    needs: build  # Only run after build passes
    
    defaults:
      run:
        working-directory: ./aethron.tech
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
        cache-dependency-path: aethron.tech/package-lock.json
        
    - name: Install dependencies
      run: npm ci
      
    - name: Build website for testing
      run: npm run build
      env:
        NODE_ENV: ci
        
    - name: Setup Chrome
      uses: browser-actions/setup-chrome@v1
      with:
        chrome-version: stable
        
    - name: Verify Chrome installation  
      run: |
        which google-chrome
        google-chrome --version
        
    - name: Start development server
      run: |
        npm run serve &
        npx wait-on http://localhost:8080 --timeout 60000
      env:
        NODE_ENV: ci
        
    - name: Run Lighthouse audit
      run: |
        echo "ðŸ” Running Lighthouse performance and quality audit..."
        npx lighthouse http://localhost:8080 \
          --chrome-flags='--headless --no-sandbox --disable-dev-shm-usage --disable-gpu --disable-extensions' \
          --output=json \
          --output-path=./lighthouse-report.json \
          --quiet \
          --only-categories=performance,accessibility,best-practices,seo
        
        # Parse and display results
        echo "ðŸ“Š Lighthouse Results:"
        node -e "
          const report = JSON.parse(require('fs').readFileSync('./lighthouse-report.json', 'utf8'));
          const categories = report.categories;
          
          console.log('');
          console.log('ðŸŽ¯ **LIGHTHOUSE AUDIT RESULTS**');
          console.log('================================');
          Object.entries(categories).forEach(([key, cat]) => {
            const score = Math.round(cat.score * 100);
            const emoji = score >= 90 ? 'ðŸŸ¢' : score >= 70 ? 'ðŸŸ¡' : 'ðŸ”´';
            console.log(\`\${emoji} \${cat.title}: \${score}/100\`);
          });
          console.log('');
          
          // Check thresholds
          const performance = Math.round(categories.performance.score * 100);
          const accessibility = Math.round(categories.accessibility.score * 100);
          const bestPractices = Math.round(categories['best-practices'].score * 100);
          const seo = Math.round(categories.seo.score * 100);
          
          if (accessibility < 90) {
            console.error('âŒ Accessibility score below 90%');
            process.exit(1);
          }
          if (performance < 70) {
            console.warn('âš ï¸  Performance score below 70%');
          }
          if (seo < 90) {
            console.warn('âš ï¸  SEO score below 90%');  
          }
          
          console.log('âœ… Lighthouse audit completed successfully!');
        "
      env:
        CHROME_PATH: /opt/hostedtoolcache/chromium/*/x64/chrome
        
    - name: Run Pa11y accessibility audit
      run: |
        echo "â™¿ Running Pa11y accessibility audit..."
        npx pa11y http://localhost:8080 \
          --config .pa11yrc.json \
          --reporter cli \
          --threshold 5 \
          --timeout 30000
          
        echo "âœ… Pa11y accessibility audit completed!"
        
    # WEBS-49: Open Graph Validation
    - name: ðŸ”— OG Tags Validation
      run: |
        echo "ðŸ” Running Open Graph tags validation..."
        
        # Run OG validation (allow it to fail but capture the result)
        set +e
        npm run validate:og
        OG_EXIT_CODE=$?
        set -e
        
        # Always show report preview if it exists
        if [ -f og-validation-report.md ]; then
          echo "ðŸ“„ OG validation report generated"
          echo ""
          echo "=== OG VALIDATION SUMMARY ==="
          head -15 og-validation-report.md | tail -10
          echo "=== (See full report in artifacts) ==="
          echo ""
        else
          echo "âŒ OG validation report not generated"
        fi
        
        # Provide guidance based on results
        if [ $OG_EXIT_CODE -eq 0 ]; then
          echo "âœ… All OG tags validation passed!"
        else
          echo "âš ï¸ OG validation found issues - check the detailed report"
          echo "ðŸ’¡ This is informational and won't fail the build"
        fi
        
    - name: Enhanced HTML validation
      run: |
        echo "ðŸ” Running enhanced HTML validation..."
        
        # Run HTMLHint with detailed reporting
        npx htmlhint "_site/**/*.html" \
          --config .htmlhintrc \
          --format compact
          
        # Additional HTML5 validation (if available)
        echo "ðŸ“‹ HTML validation summary:"
        echo "   - Files checked: $(find _site/ -name '*.html' | wc -l)"
        echo "   - HTMLHint rules: $(cat .htmlhintrc | grep -c true)"
        
        echo "âœ… Enhanced HTML validation completed!"
        
    - name: Detect Lighthouse performance regression
      run: |
        echo "ðŸ” Checking for Lighthouse performance regression..."
        PERF_SCORE=$(node -e "console.log(Math.round(JSON.parse(require('fs').readFileSync('./lighthouse-report.json', 'utf8')).categories.performance.score * 100))")
        BASELINE_FILE="lighthouse-baseline.json"
        THRESHOLD=5
        if [ -f "$BASELINE_FILE" ]; then
          BASELINE_SCORE=$(node -e "console.log(Math.round(JSON.parse(require('fs').readFileSync('$BASELINE_FILE', 'utf8')).categories.performance.score * 100))")
          echo "Baseline performance score: $BASELINE_SCORE"
          echo "Current performance score: $PERF_SCORE"
          if [ $((BASELINE_SCORE - PERF_SCORE)) -gt $THRESHOLD ]; then
            echo "âŒ Performance regression detected! Score dropped by more than $THRESHOLD points."
            exit 1
          else
            echo "âœ… No significant performance regression detected."
          fi
        else
          echo "No baseline found. Saving current Lighthouse report as baseline."
          cp lighthouse-report.json $BASELINE_FILE
        fi
      env:
        NODE_ENV: ci
        
    - name: Generate quality report
      if: always()
      run: |
        echo "ðŸ“ˆ **QUALITY AUDIT SUMMARY**" > quality-report.md
        echo "=========================" >> quality-report.md
        echo "" >> quality-report.md
        
        if [ -f lighthouse-report.json ]; then
          echo "## ðŸš€ Lighthouse Results" >> quality-report.md
          node -e "
            const report = JSON.parse(require('fs').readFileSync('./lighthouse-report.json', 'utf8'));
            const categories = report.categories;
            Object.entries(categories).forEach(([key, cat]) => {
              const score = Math.round(cat.score * 100);
              console.log(\`- **\${cat.title}**: \${score}/100\`);
            });
          " >> quality-report.md
          echo "" >> quality-report.md
        fi
        
        echo "## â™¿ Accessibility" >> quality-report.md
        echo "- Pa11y audit: Completed" >> quality-report.md
        echo "- WCAG 2.1 AA compliance checked" >> quality-report.md
        echo "" >> quality-report.md
        
        echo "## ðŸ” HTML Quality" >> quality-report.md
        echo "- HTMLHint validation: Completed" >> quality-report.md
        echo "- Files validated: $(find _site/ -name '*.html' | wc -l)" >> quality-report.md
        echo "" >> quality-report.md
        
        echo "## ðŸ”— Open Graph Tags (WEBS-49)" >> quality-report.md
        if [ -f og-validation-report.md ]; then
          echo "- OG validation: Completed" >> quality-report.md
          echo "- Pages tested: 8" >> quality-report.md
          echo "- Full report: See og-validation-report.md artifact" >> quality-report.md
        else
          echo "- OG validation: Report not generated" >> quality-report.md
        fi
        echo "" >> quality-report.md
        
        cat quality-report.md
        
    - name: Upload quality reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: quality-reports
        path: |
          aethron.tech/lighthouse-report.json
          aethron.tech/quality-report.md
          aethron.tech/og-validation-report.md
        retention-days: 30
        
    - name: âœ… Quality Summary
      run: |
        echo "ðŸŽ‰ All quality checks completed!"
        echo "âœ… Lighthouse: Performance, Accessibility, Best Practices, SEO"
        echo "âœ… Pa11y: WCAG 2.1 AA Accessibility"  
        echo "âœ… HTMLHint: Enhanced HTML validation"
        echo "ï¿½ OG Tags: Social media preview validation (WEBS-49)"
        echo "ï¿½ðŸ“Š Reports uploaded as artifacts"

  # Job 4: Create .env from GitHub Secrets
  env:
    name: Create .env from GitHub Secrets
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Create .env file from GitHub Secrets
      run: |
        echo "SMTP_HOST=${{ secrets.SMTP_HOST }}" >> aethron.tech/.env
        echo "SMTP_USER=${{ secrets.SMTP_USER }}" >> aethron.tech/.env
        echo "SMTP_PASS=${{ secrets.SMTP_PASS }}" >> aethron.tech/.env
        echo "CONTACT_RECEIVER=${{ secrets.CONTACT_RECEIVER }}" >> aethron.tech/.env
        echo "SMTP_PORT=${{ secrets.SMTP_PORT }}" >> aethron.tech/.env

  # Job 5: Dependency Review (GitHub Action)
  dependency-review:
    name: Dependency Review (GitHub Action)
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - name: Dependency Review Action
        uses: actions/dependency-review-action@v4
        with:
          fail-on-severity: high
          comment-summary-in-pr: true
          allow-licenses: MIT,Apache-2.0,BSD-2-Clause,BSD-3-Clause,ISC
          # Adjust allowed licenses as needed
          
  # Job 6: Incident Notification (GitHub Issue)
  incident-notify:
    name: Incident Notification (GitHub Issue)
    runs-on: ubuntu-latest
    needs: [lint, build, quality, env, dependency-review]
    if: failure()
    steps:
      - name: Create GitHub Issue for Incident
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const failedJobs = [
              'lint',
              'build',
              'quality',
              'env',
              'dependency-review'
            ].filter(job => core.getInput(`needs.${job}.result`) === 'failure');
            const title = `ðŸš¨ CI Incident: Workflow failed on ${{ github.ref }}`;
            const body = `### Incident detected\n\n- **Workflow:** ${{ github.workflow }}\n- **Branch/Ref:** ${{ github.ref }}\n- **Commit:** ${{ github.sha }}\n- **Failed Jobs:** ${failedJobs.join(', ') || 'Unknown'}\n- **Actor:** ${{ github.actor }}\n- **Run:** [View run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})\n\nPlease investigate and resolve the incident.\n`;
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title,
              body,
              labels: ['ci-incident', 'automated']
            });
            
  # Job 7: Error Budget Tracking & Alerting
  error-budget:
    name: Error Budget Tracking & Alerting
    runs-on: ubuntu-latest
    needs: [lint, build, quality, env, dependency-review]
    if: always()
    steps:
      - name: Track error budget in GitHub Issue
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            // Settings
            const ERROR_BUDGET_ISSUE_TITLE = 'ðŸš¦ CI/CD Error Budget Log';
            const ERROR_BUDGET_ALERT_THRESHOLD = 0.05; // 5% error budget
            const WINDOW_SIZE = 30; // Last 30 runs
            const runStatus = '${{ job.status }}';
            const runTime = new Date().toISOString();
            // 1. Find or create the error budget log issue
            let issue;
            const { data: issues } = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'error-budget-log',
              per_page: 5
            });
            issue = issues.find(i => i.title === ERROR_BUDGET_ISSUE_TITLE);
            if (!issue) {
              const { data: newIssue } = await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: ERROR_BUDGET_ISSUE_TITLE,
                body: 'This issue logs the last 30 CI/CD workflow results for error budget tracking.\n\nFormat: `timestamp | status | run_id`',
                labels: ['error-budget-log', 'automated']
              });
              issue = newIssue;
            }
            // 2. Append this run to the log (as a comment)
            const logLine = `${runTime} | ${runStatus} | ${{ github.run_id }}`;
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issue.number,
              body: logLine
            });
            // 3. Get last WINDOW_SIZE results
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issue.number,
              per_page: WINDOW_SIZE,
              direction: 'desc',
              sort: 'created'
            });
            const recent = comments.slice(0, WINDOW_SIZE).map(c => c.body);
            const failures = recent.filter(l => l.includes('failure')).length;
            const errorRate = failures / Math.max(recent.length, 1);
            // 4. Alert if error budget exceeded
            if (errorRate > ERROR_BUDGET_ALERT_THRESHOLD) {
              const alertTitle = `ðŸš¨ Error Budget Exceeded: ${Math.round(errorRate*100)}% failures in last ${recent.length} runs`;
              const alertBody = `Error budget exceeded!\n\n- **Threshold:** ${ERROR_BUDGET_ALERT_THRESHOLD*100}%\n- **Actual:** ${Math.round(errorRate*100)}%\n- **Window:** Last ${recent.length} runs\n- **Time:** ${runTime}\n\nSee [error budget log issue #${issue.number}](https://github.com/${{ github.repository }}/issues/${issue.number}) for details.`;
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: alertTitle,
                body: alertBody,
                labels: ['error-budget', 'automated']
              });
            }
